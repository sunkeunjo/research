{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VaderÎ•º ÌÜµÌïú Í∞êÏ†ïÎ∂ÑÏÑù ÏàòÌñâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[['‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è', 'üíôüç™'], ['üëè', 'we', \"'re\", 'pretty'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[['This', 'is', 'awesome', '!', '!', '!', 'üëèüëèüëè...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[['Build', 'with', 'immortal', 'love', 'üëë'], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[['.', '.', '.', '.', '#', 'staugustine', '#',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[['.', '.', '.', '.', '#', 'boca', '#', 'bocar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                      comment_token\n",
       "0        1  [['‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è', 'üíôüç™'], ['üëè', 'we', \"'re\", 'pretty'...\n",
       "1        2  [['This', 'is', 'awesome', '!', '!', '!', 'üëèüëèüëè...\n",
       "2        3  [['Build', 'with', 'immortal', 'love', 'üëë'], [...\n",
       "3        4  [['.', '.', '.', '.', '#', 'staugustine', '#',...\n",
       "4        5  [['.', '.', '.', '.', '#', 'boca', '#', 'bocar..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_data():\n",
    "    hyatt= pd.read_csv(\"hyatt_comment_final\",index_col=[0]).reset_index()\n",
    "    hilton=pd.read_csv(\"hilton_comment_final\",index_col=[0]).reset_index()\n",
    "    holiday=pd.read_csv(\"holiday_comment_final\",index_col=[0]).reset_index()\n",
    "    wyndham=pd.read_csv(\"wyndham_comment_final\",index_col=[0]).reset_index()\n",
    "    \n",
    "    return (hilton,hyatt,holiday,wyndham)\n",
    "hilton,hyatt,holiday,wyndham=read_data()\n",
    "hilton.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "import ast \n",
    "def string_to_list(df,columns):\n",
    "    for col in columns:\n",
    "        df[col]=df[col].apply(lambda x: ast.literal_eval(x))\n",
    "        \n",
    "for hotel in (hilton,hyatt,holiday,wyndham):\n",
    "    string_to_list(hotel,[\"comment_token\"])\n",
    "print(type(hilton[\"comment_token\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è üíôüç™\n",
      "üëè we 're pretty excited about it !\n",
      "ü§§‚ù§Ô∏è enjoy ! We hope you can try it at home üòç\n",
      "OMG WHAT THIS IS AWESOME ü§Øü§Øü§Ø\n",
      "I miss staying at Hilton hotels so much ! So my dad made these for me this morning haha\n",
      "This is the best news ! ! ! Can ‚Äô t wait to bake these at home üç™ ‚ù§Ô∏èTHANK YOU\n",
      "‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è super team thank you you 're very welcome !\n",
      "I love these cookies . We must make them when this is over . yes please ! ! ! do n't forget to tag us ! We ca n't wait to see how they turn out .\n",
      "ü§§ü§§\n",
      "IMPORTANT God I miss those cookies !\n",
      "remember the yummy cookie ? ? üç™üç™ yup\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[0.0, 0.7088, 0.75, 0.7034, 0.4003, 0.7249, 0.8746, 0.9008, 0.0, 0.5147, 0.5803, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.08, 0.0, 0.0, 0.0, 0.0, 0.188, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.596, 0.444, 0.492, 0.165, 0.281, 0.625, 0.325, 0.0, 0.578, 0.429, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "senti_analyzer= SentimentIntensityAnalyzer()\n",
    "score_list=[]\n",
    "pos_list=[]\n",
    "neg_list=[]\n",
    "for comment_list in hilton[\"comment_token\"][0]:\n",
    "    sentence=\" \".join(comment_list)\n",
    "    print(sentence)\n",
    "    senti_scores=senti_analyzer.polarity_scores(sentence)\n",
    "    score_list.append(senti_scores[\"compound\"])\n",
    "    pos_list.append(senti_scores[\"pos\"])\n",
    "    neg_list.append(senti_scores[\"neg\"])\n",
    "print(score_list)\n",
    "print(neg_list)\n",
    "print(pos_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_token</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[[ü§ó, üòÄ], [Sounds, awesome, !, üëçüèºüòé‚ù§Ô∏è, üòÄ, we, co...</td>\n",
       "      <td>[0.0, 0.8165, 0.0, 0.0, 0.0, 0.3612, 0.937, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[[I, love, what, they, doing, üòç, we, absolutel...</td>\n",
       "      <td>[0.6696, 0.0, 0.0, 0.9811, 0.6705]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[[hi, ,, I, would, like, to, know, how, can, I...</td>\n",
       "      <td>[0.7717, 0.0, 0.0, 0.8906, 0.836]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[[I, booked, chandighar, and, amritsar, but, I...</td>\n",
       "      <td>[0.797, 0.5411, 0.8302, 0.0, 0.4926, 0.1007, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[[I, 'm, missing, Grand, Hyatt, Rio, de, Janei...</td>\n",
       "      <td>[0.9057, 0.0, 0.915, 0.0, 0.7405, 0.4404, 0.72...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                      comment_token  \\\n",
       "0        1  [[ü§ó, üòÄ], [Sounds, awesome, !, üëçüèºüòé‚ù§Ô∏è, üòÄ, we, co...   \n",
       "1        2  [[I, love, what, they, doing, üòç, we, absolutel...   \n",
       "2        3  [[hi, ,, I, would, like, to, know, how, can, I...   \n",
       "3        4  [[I, booked, chandighar, and, amritsar, but, I...   \n",
       "4        5  [[I, 'm, missing, Grand, Hyatt, Rio, de, Janei...   \n",
       "\n",
       "                                            compound  \n",
       "0  [0.0, 0.8165, 0.0, 0.0, 0.0, 0.3612, 0.937, 0....  \n",
       "1                 [0.6696, 0.0, 0.0, 0.9811, 0.6705]  \n",
       "2                  [0.7717, 0.0, 0.0, 0.8906, 0.836]  \n",
       "3  [0.797, 0.5411, 0.8302, 0.0, 0.4926, 0.1007, 0...  \n",
       "4  [0.9057, 0.0, 0.915, 0.0, 0.7405, 0.4404, 0.72...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "def compound_score(text):\n",
    "    senti_analyzer=SentimentIntensityAnalyzer()\n",
    "    compound_list=[]\n",
    "    for comment_list in text:\n",
    "        sentence=\" \".join(comment_list)\n",
    "        senti_scores=senti_analyzer.polarity_scores(sentence)\n",
    "        compound_list.append(senti_scores[\"compound\"])\n",
    "    return compound_list\n",
    "\n",
    "for hotel in (hilton,hyatt,holiday,wyndham):\n",
    "    hotel[\"compound\"]=hotel[\"comment_token\"].apply(lambda x : compound_score(x))\n",
    "hyatt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_score(text):\n",
    "    senti_analyzer=SentimentIntensityAnalyzer()\n",
    "    pos_list=[]\n",
    "    for comment_list in text:\n",
    "        sentence=\" \".join(comment_list)\n",
    "        senti_scores=senti_analyzer.polarity_scores(sentence)\n",
    "        pos_list.append(senti_scores[\"pos\"])\n",
    "    return pos_list\n",
    "\n",
    "def negative_score(text):\n",
    "    senti_analyzer=SentimentIntensityAnalyzer()\n",
    "    neg_list=[]\n",
    "    for comment_list in text:\n",
    "        sentence=\" \".join(comment_list)\n",
    "        senti_scores=senti_analyzer.polarity_scores(sentence)\n",
    "        neg_list.append(senti_scores[\"neg\"])\n",
    "    return neg_list\n",
    "for hotel in (hilton,hyatt,holiday,wyndham):\n",
    "    hotel[\"positive\"]=hotel[\"comment_token\"].apply(lambda x : positive_score(x))\n",
    "    hotel[\"negative\"]=hotel[\"comment_token\"].apply(lambda x : negative_score(x))\n",
    "hyatt.head()\n",
    "\n",
    "def save_data(hyatt,hilton,holiday,wyndham):\n",
    "    hyatt.to_csv(\"hyatt_comment_final\",index=False)\n",
    "    hilton.to_csv(\"hilton_comment_final\",index=False)\n",
    "    holiday.to_csv(\"holiday_comment_final\",index=False)\n",
    "    wyndham.to_csv(\"wyndham_comment_final\",index=False)\n",
    "save_data(hyatt,hilton,holiday,wyndham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_token</th>\n",
       "      <th>compound</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[[ü§ó, üòÄ], [Sounds, awesome, !, üëçüèºüòé‚ù§Ô∏è, üòÄ, we, co...</td>\n",
       "      <td>[0.0, 0.8165, 0.0, 0.0, 0.0, 0.3612, 0.937, 0....</td>\n",
       "      <td>[0.0, 0.651, 0.0, 0.0, 0.0, 0.714, 0.525, 0.55...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[[I, love, what, they, doing, üòç, we, absolutel...</td>\n",
       "      <td>[0.6696, 0.0, 0.0, 0.9811, 0.6705]</td>\n",
       "      <td>[0.391, 0.0, 0.0, 0.614, 0.161]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.057]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[[hi, ,, I, would, like, to, know, how, can, I...</td>\n",
       "      <td>[0.7717, 0.0, 0.0, 0.8906, 0.836]</td>\n",
       "      <td>[0.278, 0.0, 0.0, 0.234, 0.279]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[[I, booked, chandighar, and, amritsar, but, I...</td>\n",
       "      <td>[0.797, 0.5411, 0.8302, 0.0, 0.4926, 0.1007, 0...</td>\n",
       "      <td>[0.196, 0.411, 0.23, 0.0, 0.516, 0.16, 0.444, ...</td>\n",
       "      <td>[0.105, 0.0, 0.0, 0.0, 0.0, 0.14, 0.0, 0.059, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[[I, 'm, missing, Grand, Hyatt, Rio, de, Janei...</td>\n",
       "      <td>[0.9057, 0.0, 0.915, 0.0, 0.7405, 0.4404, 0.72...</td>\n",
       "      <td>[0.339, 0.0, 0.418, 0.0, 0.116, 0.172, 0.388, ...</td>\n",
       "      <td>[0.052, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                      comment_token  \\\n",
       "0        1  [[ü§ó, üòÄ], [Sounds, awesome, !, üëçüèºüòé‚ù§Ô∏è, üòÄ, we, co...   \n",
       "1        2  [[I, love, what, they, doing, üòç, we, absolutel...   \n",
       "2        3  [[hi, ,, I, would, like, to, know, how, can, I...   \n",
       "3        4  [[I, booked, chandighar, and, amritsar, but, I...   \n",
       "4        5  [[I, 'm, missing, Grand, Hyatt, Rio, de, Janei...   \n",
       "\n",
       "                                            compound  \\\n",
       "0  [0.0, 0.8165, 0.0, 0.0, 0.0, 0.3612, 0.937, 0....   \n",
       "1                 [0.6696, 0.0, 0.0, 0.9811, 0.6705]   \n",
       "2                  [0.7717, 0.0, 0.0, 0.8906, 0.836]   \n",
       "3  [0.797, 0.5411, 0.8302, 0.0, 0.4926, 0.1007, 0...   \n",
       "4  [0.9057, 0.0, 0.915, 0.0, 0.7405, 0.4404, 0.72...   \n",
       "\n",
       "                                            positive  \\\n",
       "0  [0.0, 0.651, 0.0, 0.0, 0.0, 0.714, 0.525, 0.55...   \n",
       "1                    [0.391, 0.0, 0.0, 0.614, 0.161]   \n",
       "2                    [0.278, 0.0, 0.0, 0.234, 0.279]   \n",
       "3  [0.196, 0.411, 0.23, 0.0, 0.516, 0.16, 0.444, ...   \n",
       "4  [0.339, 0.0, 0.418, 0.0, 0.116, 0.172, 0.388, ...   \n",
       "\n",
       "                                            negative  \n",
       "0      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "1                        [0.0, 0.0, 0.0, 0.0, 0.057]  \n",
       "2                          [0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "3  [0.105, 0.0, 0.0, 0.0, 0.0, 0.14, 0.0, 0.059, ...  \n",
       "4  [0.052, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0, 0....  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyatt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    hyatt= pd.read_csv(\"hyatt_final\",index_col=[0]).reset_index()\n",
    "    hilton=pd.read_csv(\"hilton_final\",index_col=[0]).reset_index()\n",
    "    holiday=pd.read_csv(\"holiday_final\",index_col=[0]).reset_index()\n",
    "    wyndham=pd.read_csv(\"wyndham_final\",index_col=[0]).reset_index()\n",
    "    \n",
    "    return (hilton,hyatt,holiday,wyndham)\n",
    "\n",
    "def string_to_list(df,columns):\n",
    "    for col in columns:\n",
    "        df[col]=df[col].apply(lambda x: ast.literal_eval(x))\n",
    "        \n",
    "        \n",
    "hilton,hyatt,holiday,wyndham=read_data()  \n",
    "\n",
    "for hotel in (hilton,hyatt,holiday,wyndham):\n",
    "    string_to_list(hotel,[\"caption_token\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>caption</th>\n",
       "      <th>id</th>\n",
       "      <th>profile</th>\n",
       "      <th>type</th>\n",
       "      <th>caption_and_hashtags</th>\n",
       "      <th>is_video</th>\n",
       "      <th>view_count</th>\n",
       "      <th>video_duration</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "      <th>caption_tag</th>\n",
       "      <th>real_ugc</th>\n",
       "      <th>caption_token</th>\n",
       "      <th>compound</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-09 16:33:28</td>\n",
       "      <td>Over the past few weeks, we‚Äôve gotten lots of ...</td>\n",
       "      <td>1</td>\n",
       "      <td>hilton</td>\n",
       "      <td>GraphVideo</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>1730.0</td>\n",
       "      <td>30.3</td>\n",
       "      <td>194</td>\n",
       "      <td>29</td>\n",
       "      <td>['@doubletree)']</td>\n",
       "      <td>False</td>\n",
       "      <td>[Over, the, past, few, weeks, ,, we, ‚Äô, ve, go...</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-06 12:37:22</td>\n",
       "      <td>One million ‚Äòthank-yous‚Äô to the frontline medi...</td>\n",
       "      <td>2</td>\n",
       "      <td>hilton</td>\n",
       "      <td>GraphImage</td>\n",
       "      <td>['hotelsforheroes']</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>412</td>\n",
       "      <td>19</td>\n",
       "      <td>['@AmericanExpress']</td>\n",
       "      <td>False</td>\n",
       "      <td>[One, million, ‚Äò, thank-yous, ‚Äô, to, the, fron...</td>\n",
       "      <td>0.9022</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-03 15:31:01</td>\n",
       "      <td>We‚Äôre joining with hotels across the world to ...</td>\n",
       "      <td>3</td>\n",
       "      <td>hilton</td>\n",
       "      <td>GraphSidecar</td>\n",
       "      <td>['hope']</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>418</td>\n",
       "      <td>7</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>[We, ‚Äô, re, joining, with, hotels, across, the...</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-11 15:54:11</td>\n",
       "      <td>We tend to lose track of things during a stay ...</td>\n",
       "      <td>4</td>\n",
       "      <td>hilton</td>\n",
       "      <td>GraphImage</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>['@embassysuitesstaugustinebeach:']</td>\n",
       "      <td>False</td>\n",
       "      <td>[We, tend, to, lose, track, of, things, during...</td>\n",
       "      <td>-0.4019</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-09 18:02:10</td>\n",
       "      <td>From Lake Boca to the beach, @bocaresort will ...</td>\n",
       "      <td>5</td>\n",
       "      <td>hilton</td>\n",
       "      <td>GraphImage</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>227</td>\n",
       "      <td>7</td>\n",
       "      <td>['@bocaresort']</td>\n",
       "      <td>False</td>\n",
       "      <td>[From, Lake, Boca, to, the, beach, ,, will, ta...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date                                            caption  id  \\\n",
       "0  2020-04-09 16:33:28  Over the past few weeks, we‚Äôve gotten lots of ...   1   \n",
       "1  2020-04-06 12:37:22  One million ‚Äòthank-yous‚Äô to the frontline medi...   2   \n",
       "2  2020-04-03 15:31:01  We‚Äôre joining with hotels across the world to ...   3   \n",
       "3  2020-03-11 15:54:11  We tend to lose track of things during a stay ...   4   \n",
       "4  2020-03-09 18:02:10  From Lake Boca to the beach, @bocaresort will ...   5   \n",
       "\n",
       "  profile          type caption_and_hashtags  is_video  view_count  \\\n",
       "0  hilton    GraphVideo                   []      True      1730.0   \n",
       "1  hilton    GraphImage  ['hotelsforheroes']     False         NaN   \n",
       "2  hilton  GraphSidecar             ['hope']     False         NaN   \n",
       "3  hilton    GraphImage                   []     False         NaN   \n",
       "4  hilton    GraphImage                   []     False         NaN   \n",
       "\n",
       "   video_duration  likes  comments                          caption_tag  \\\n",
       "0            30.3    194        29                     ['@doubletree)']   \n",
       "1             NaN    412        19                 ['@AmericanExpress']   \n",
       "2             NaN    418         7                                   []   \n",
       "3             NaN     98         1  ['@embassysuitesstaugustinebeach:']   \n",
       "4             NaN    227         7                      ['@bocaresort']   \n",
       "\n",
       "   real_ugc                                      caption_token  compound  \\\n",
       "0     False  [Over, the, past, few, weeks, ,, we, ‚Äô, ve, go...    0.9100   \n",
       "1     False  [One, million, ‚Äò, thank-yous, ‚Äô, to, the, fron...    0.9022   \n",
       "2     False  [We, ‚Äô, re, joining, with, hotels, across, the...    0.8750   \n",
       "3     False  [We, tend, to, lose, track, of, things, during...   -0.4019   \n",
       "4     False  [From, Lake, Boca, to, the, beach, ,, will, ta...    0.0000   \n",
       "\n",
       "   positive  negative  \n",
       "0     0.178     0.019  \n",
       "1     0.189     0.000  \n",
       "2     0.312     0.000  \n",
       "3     0.000     0.172  \n",
       "4     0.000     0.000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def compound_score(text):\n",
    "    senti_analyzer=SentimentIntensityAnalyzer()\n",
    "    sentence=\" \".join(text)\n",
    "    senti_scores=senti_analyzer.polarity_scores(sentence)\n",
    "    \n",
    "    return senti_scores[\"compound\"]\n",
    "\n",
    "def pos_score(text):\n",
    "    senti_analyzer=SentimentIntensityAnalyzer()\n",
    "    sentence=\" \".join(text)\n",
    "    senti_scores=senti_analyzer.polarity_scores(sentence)\n",
    "    \n",
    "    return senti_scores[\"pos\"]\n",
    "\n",
    "def neg_score(text):\n",
    "    senti_analyzer=SentimentIntensityAnalyzer()\n",
    "    sentence=\" \".join(text)\n",
    "    senti_scores=senti_analyzer.polarity_scores(sentence)\n",
    "    \n",
    "    return senti_scores[\"neg\"]\n",
    "\n",
    "for hotel in (hilton,hyatt,holiday,wyndham):\n",
    "    hotel[\"compound\"]=hotel[\"caption_token\"].apply(lambda x : compound_score(x))\n",
    "    hotel[\"positive\"]=hotel[\"caption_token\"].apply(lambda x : pos_score(x))\n",
    "    hotel[\"negative\"]=hotel[\"caption_token\"].apply(lambda x : neg_score(x))\n",
    "    \n",
    "hilton.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(hyatt,hilton,holiday,wyndham):\n",
    "    hyatt.to_csv(\"hyattt_final\",index=False)\n",
    "    hilton.to_csv(\"hiltont_final\",index=False)\n",
    "    holiday.to_csv(\"holiday_final\",index=False)\n",
    "    wyndham.to_csv(\"wyndham_final\",index=False)\n",
    "save_data(hyatt,hilton,holiday,wyndham)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
